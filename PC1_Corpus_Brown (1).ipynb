{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "sin suavizacion:"
      ],
      "metadata": {
        "id": "jKlpUO399Yw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import brown\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "nltk.download('brown')\n",
        "\n",
        "brown_sentences = brown.sents(categories=None)\n",
        "\n",
        "def preprocess_sentences(sentences):\n",
        "    preprocessed = []\n",
        "    for sentence in sentences:\n",
        "        sentence = [word.lower() for word in sentence if word.isalpha()]\n",
        "        preprocessed.append(sentence)\n",
        "    return preprocessed\n",
        "\n",
        "preprocessed_sentences = preprocess_sentences(brown_sentences)\n",
        "\n",
        "def generate_ngrams(sentence, n):\n",
        "    ngrams = zip(*[sentence[i:] for i in range(n)])\n",
        "    return list(ngrams)\n",
        "\n",
        "class SimpleNgramModel:\n",
        "    def __init__(self, sentences, n):\n",
        "        self.n = n\n",
        "        self.ngram_counts = defaultdict(Counter)\n",
        "        self.unigram_counts = Counter()\n",
        "\n",
        "        for sentence in sentences:\n",
        "            sentence = ['<s>'] * (n - 1) + sentence + ['</s>']\n",
        "            for i in range(1, n + 1):  # Creamos los gramas\n",
        "                ngrams = generate_ngrams(sentence, i)\n",
        "                for ngram in ngrams:\n",
        "                    self.ngram_counts[i][ngram] += 1\n",
        "                    if i == 1:\n",
        "                        self.unigram_counts[ngram] += 1\n",
        "\n",
        "    def get_probability(self, ngram):\n",
        "        count_ngram = self.ngram_counts[len(ngram)][ngram]\n",
        "\n",
        "        if len(ngram) == 1:\n",
        "            total_count = sum(self.unigram_counts.values())\n",
        "        else:\n",
        "            total_count = sum(self.ngram_counts[len(ngram) - 1][ngram[:-1]] for ngram in self.ngram_counts[len(ngram) - 1])\n",
        "\n",
        "        if total_count > 0:\n",
        "            return count_ngram / total_count\n",
        "        else:\n",
        "            return 0  # Si no hay n-gramas disponibles, se devuelve una probabilidad 0\n",
        "\n",
        "    def generate_text(self, num_words=20):\n",
        "        generated_sentence = ['<s>'] * (self.n - 1)\n",
        "        for _ in range(num_words):\n",
        "            next_word_candidates = []\n",
        "            for ngram in self.ngram_counts[self.n]:\n",
        "                if ngram[:-1] == tuple(generated_sentence[-(self.n - 1):]):\n",
        "                    next_word_candidates.append((ngram[-1], self.get_probability(ngram)))\n",
        "\n",
        "            next_word_candidates.sort(key=lambda x: x[1], reverse=True)\n",
        "            next_word = next_word_candidates[0][0] if next_word_candidates else '</s>'\n",
        "\n",
        "            if next_word == '</s>':\n",
        "                break\n",
        "            generated_sentence.append(next_word)\n",
        "\n",
        "        return \" \".join(generated_sentence[self.n - 1:])\n",
        "\n",
        "# Entrenamos el modelo y generamos el texto\n",
        "n = 3\n",
        "simple_model = SimpleNgramModel(preprocessed_sentences[:50000], n)\n",
        "\n",
        "# Generaramos el texto a partir del modelo entrenado\n",
        "simple_generated_text = simple_model.generate_text(num_words=30)\n",
        "print(\"Texto generado sin suavización:\")\n",
        "print(simple_generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "JUmkEhh03NNl",
        "outputId": "d43044d8-eeb0-4bad-8d5f-036c230aa0d4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2b0d336f864d>\u001b[0m in \u001b[0;36m<cell line: 76>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;31m# Generar texto a partir del modelo entrenado\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0msimple_generated_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimple_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Texto generado sin suavización:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_generated_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-2b0d336f864d>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(self, num_words)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mngram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngram_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mngram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_sentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                     \u001b[0mnext_word_candidates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_probability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mnext_word_candidates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-2b0d336f864d>\u001b[0m in \u001b[0;36mget_probability\u001b[0;34m(self, ngram)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mtotal_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munigram_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mtotal_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngram_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mngram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngram_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtotal_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-2b0d336f864d>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mtotal_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munigram_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mtotal_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngram_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mngram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngram_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtotal_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sequence_probability(model, sequence):\n",
        "    ngrams = generate_ngrams(sequence, model.n)\n",
        "    total_prob = 1.0\n",
        "    for ngram in ngrams:\n",
        "        prob = model.get_probability(ngram)\n",
        "        total_prob *= prob if prob > 0 else 1e-10\n",
        "    return total_prob"
      ],
      "metadata": {
        "id": "UemddDz__vFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suavización de interpolacion"
      ],
      "metadata": {
        "id": "UGv6a69h_gDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import brown\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "nltk.download('brown')\n",
        "\n",
        "brown_sentences = brown.sents(categories=None)\n",
        "\n",
        "def preprocess_sentences(sentences):\n",
        "    preprocessed = []\n",
        "    for sentence in sentences:\n",
        "        sentence = [word.lower() for word in sentence if word.isalpha()]\n",
        "        preprocessed.append(sentence)\n",
        "    return preprocessed\n",
        "\n",
        "preprocessed_sentences = preprocess_sentences(brown_sentences)\n",
        "\n",
        "def generate_ngrams(sentence, n):\n",
        "    ngrams = zip(*[sentence[i:] for i in range(n)])\n",
        "    return list(ngrams)\n",
        "\n",
        "class InterpolatedNgramModel:\n",
        "    def __init__(self, sentences, n, lambdas=None):\n",
        "        self.n = n\n",
        "        self.lambdas = lambdas if lambdas else [1/n] * n\n",
        "        self.ngram_counts = defaultdict(Counter)\n",
        "        self.unigram_counts = Counter()\n",
        "\n",
        "        for sentence in sentences:\n",
        "            sentence = ['<s>'] * (n - 1) + sentence + ['</s>']\n",
        "            for i in range(1, n + 1):\n",
        "                ngrams = generate_ngrams(sentence, i)\n",
        "                for ngram in ngrams:\n",
        "                    self.ngram_counts[i][ngram] += 1\n",
        "                    if i == 1:\n",
        "                        self.unigram_counts[ngram] += 1\n",
        "\n",
        "    def get_probability(self, ngram):\n",
        "        total_prob = 0\n",
        "        for i in range(1, len(ngram) + 1):\n",
        "            lambda_weight = self.lambdas[i - 1]\n",
        "            prefix = tuple(ngram[-i:])\n",
        "            if i == 1:\n",
        "                count_ngram = self.unigram_counts[prefix]\n",
        "                total_count = sum(self.unigram_counts.values())\n",
        "            else:\n",
        "                count_ngram = self.ngram_counts[i][prefix]\n",
        "                total_count = sum(self.ngram_counts[i-1][prefix[:-1]] for prefix in self.ngram_counts[i-1])\n",
        "\n",
        "            prob_ngram = count_ngram / total_count if total_count > 0 else 0\n",
        "            total_prob += lambda_weight * prob_ngram\n",
        "        return total_prob\n",
        "\n",
        "    def generate_text(self, num_words=20):\n",
        "        generated_sentence = ['<s>'] * (self.n - 1)\n",
        "        for _ in range(num_words):\n",
        "            next_word_candidates = []\n",
        "            for ngram in self.ngram_counts[self.n]:\n",
        "                if ngram[:-1] == tuple(generated_sentence[-(self.n - 1):]):\n",
        "                    next_word_candidates.append((ngram[-1], self.get_probability(ngram)))\n",
        "\n",
        "            next_word_candidates.sort(key=lambda x: x[1], reverse=True)\n",
        "            next_word = next_word_candidates[0][0] if next_word_candidates else '</s>'\n",
        "\n",
        "            if next_word == '</s>':\n",
        "                break\n",
        "            generated_sentence.append(next_word)\n",
        "\n",
        "        return \" \".join(generated_sentence[self.n - 1:])\n",
        "\n",
        "n = 3  # Tri-gramas\n",
        "model = InterpolatedNgramModel(preprocessed_sentences[:50000], n, lambdas=[0.1, 0.3, 0.6])\n",
        "\n",
        "generated_text = model.generate_text(num_words=30)\n",
        "print(\"Texto generado:\")\n"
      ],
      "metadata": {
        "id": "cd5bGEzOuGCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "test_sequence = ['the', 'news', 'is', 'important', 'for', 'the', 'community']\n",
        "\n",
        "interpolated_prob = sequence_probability(model, test_sequence)\n",
        "\n",
        "simple_prob = sequence_probability(simple_model, test_sequence)\n",
        "\n",
        "# Gráfico comparativo\n",
        "models = ['Con Suavización (Interpolación)', 'Sin Suavización']\n",
        "probabilities = [interpolated_prob, simple_prob]\n",
        "print(f\"Las probabilidades son: {probabilities}\")\n",
        "plt.bar(models, probabilities, color=['blue', 'green'])\n",
        "plt.title('Comparación de Probabilidades de Secuencia entre Modelos')\n",
        "plt.ylabel('Probabilidad')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jj1oAD5u_02O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suavizado Backoff"
      ],
      "metadata": {
        "id": "Cf_se9hQ_ind"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import brown\n",
        "from collections import defaultdict, Counter\n",
        "import random\n",
        "\n",
        "nltk.download('brown')\n",
        "\n",
        "brown_sentences = brown.sents(categories='news')\n",
        "\n",
        "def preprocess_sentences(sentences):\n",
        "    preprocessed = []\n",
        "    for sentence in sentences:\n",
        "        sentence = [word.lower() for word in sentence if word.isalpha()]\n",
        "        preprocessed.append(sentence)\n",
        "    return preprocessed\n",
        "\n",
        "preprocessed_sentences = preprocess_sentences(brown_sentences)\n",
        "\n",
        "def generate_ngrams(sentence, n):\n",
        "    ngrams = zip(*[sentence[i:] for i in range(n)])\n",
        "    return list(ngrams)\n",
        "\n",
        "class BackoffNgramModel:\n",
        "    def __init__(self, sentences, n):\n",
        "        self.n = n\n",
        "        self.ngram_counts = defaultdict(Counter)\n",
        "        self.unigram_counts = Counter()\n",
        "\n",
        "        for sentence in sentences:\n",
        "            sentence = ['<s>'] * (n - 1) + sentence + ['</s>']\n",
        "            for i in range(1, n + 1):\n",
        "                ngrams = generate_ngrams(sentence, i)\n",
        "                for ngram in ngrams:\n",
        "                    self.ngram_counts[i][ngram] += 1\n",
        "                    if i == 1:\n",
        "                        self.unigram_counts[ngram] += 1\n",
        "\n",
        "    def get_probability(self, ngram):\n",
        "        for i in range(len(ngram), 0, -1):\n",
        "            prefix = tuple(ngram[-i:])\n",
        "            count_ngram = self.ngram_counts[i][prefix]\n",
        "\n",
        "            if i > 1:\n",
        "                total_count = sum(self.ngram_counts[i-1][prefix[:-1]] for prefix in self.ngram_counts[i-1])\n",
        "            else:\n",
        "                total_count = sum(self.unigram_counts.values())\n",
        "\n",
        "            if count_ngram > 0 and total_count > 0:\n",
        "                return count_ngram / total_count\n",
        "\n",
        "        return 1e-7\n",
        "\n",
        "    def generate_text(self, num_words=20):\n",
        "        generated_sentence = ['<s>'] * (self.n - 1)\n",
        "        for _ in range(num_words):\n",
        "            next_word_candidates = []\n",
        "            for ngram in self.ngram_counts[self.n]:\n",
        "                if ngram[:-1] == tuple(generated_sentence[-(self.n - 1):]):\n",
        "                    next_word_candidates.append((ngram[-1], self.get_probability(ngram)))\n",
        "\n",
        "            next_word_candidates.sort(key=lambda x: x[1], reverse=True)\n",
        "            next_word = next_word_candidates[0][0] if next_word_candidates else '</s>'\n",
        "\n",
        "            if next_word == '</s>':\n",
        "                break\n",
        "            generated_sentence.append(next_word)\n",
        "\n",
        "        return \" \".join(generated_sentence[self.n - 1:])\n",
        "\n",
        "n = 3\n",
        "model = BackoffNgramModel(preprocessed_sentences[:50000], n)\n",
        "\n",
        "generated_text = model.generate_text(num_words=30)\n",
        "print(\"Texto generado:\")\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "id": "UQ0hqP09wjzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "test_sequence = ['the', 'quick', 'brown', 'fox', 'jumps']\n",
        "\n",
        "interpolated_prob = sequence_probability(model, test_sequence)\n",
        "\n",
        "simple_prob = sequence_probability(simple_model, test_sequence)\n",
        "\n",
        "models = ['Con Suavización (Backoff)', 'Sin Suavización']\n",
        "probabilities = [interpolated_prob, simple_prob]\n",
        "print(f\"Las probabilidades son: {probabilities}\")\n",
        "plt.bar(models, probabilities, color=['blue', 'green'])\n",
        "plt.title('Comparación de Probabilidades de Secuencia entre Modelos')\n",
        "plt.ylabel('Probabilidad')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "l0uAmtCF_16W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}